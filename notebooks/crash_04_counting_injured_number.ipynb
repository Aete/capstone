{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crash_04_counting_injured_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for counting hourly injured/killed people at each segment and intersections (node & short segment). The notebook follows chapters like below:\n",
    "\n",
    "- 1. short segment\n",
    "- 2. node\n",
    "- 3. segment <br><br>\n",
    "\n",
    "A Chart (number of injured/killed people) in the dashboard (https://workzone-collision-analysis.github.io/capstone/dashboard/) was drawn based on the csv files that were created through this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. short segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that you run the 'shst_02_extract_short_segments' notebook to get the 'shst_short_segment_centroid.shp'\n",
    "# import a shapefile of the short segment centroid\n",
    "gdf_short_segment = gpd.read_file('../data/sharedstreets_geometry/short_segment/shst_short_segment_centroid.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that you run the 'crash_02_define_Intersection_crash' notebook to get the 'crash_short_segment.shpp'\n",
    "# import crash dataset\n",
    "gdf_crash_short_segment = gpd.read_file('../data/cleaned_data/crash_seperated/crash_short_segment/crash_short_segment.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['collision_', 'nearest_id', 'crash_date', 'crash_time', 'borough',\n",
       "       'zip_code', 'on_street_', 'cross_stre', 'off_street', 'number_of_',\n",
       "       'number_o_1', 'number_o_2', 'number_o_3', 'number_o_4', 'number_o_5',\n",
       "       'number_o_6', 'number_o_7', 'contributi', 'contribu_1', 'contribu_2',\n",
       "       'contribu_3', 'contribu_4', 'vehicle_ty', 'vehicle__1', 'vehicle__2',\n",
       "       'vehicle__3', 'vehicle__4', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_crash_short_segment.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "gdf_crash_short_segment = gdf_crash_short_segment.rename(columns={'collision_':'collision_id',\n",
    "                                                                  'number_of_': 'number_of_injured',\n",
    "                                                                  'number_o_1': 'number_of_killed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type of crash_time column\n",
    "gdf_crash_short_segment['crash_time'] = pd.to_datetime(gdf_crash_short_segment['crash_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for hour when crash occure\n",
    "gdf_crash_short_segment['hour'] = gdf_crash_short_segment['crash_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by 'nearest_id' ('nearest_id' is an Sharedstreet geometry id of the short segment)\n",
    "df_crash_short_segment_hourly_injured =  gdf_crash_short_segment[['nearest_id',\n",
    "                                                                   'hour',\n",
    "                                                                   'number_of_injured']].groupby(['nearest_id',\n",
    "                                                                                           'hour'],\n",
    "                                                                                            as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list of hours in a day and short segments\n",
    "hourly_range = list(range(0,24))\n",
    "list_short_segment_id =gdf_short_segment['id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list of empty dataframe per segment. In each empty dataframe, 24 rows will be created per segments\n",
    "list_empty_dataframe = []\n",
    "for i in list_short_segment_id:\n",
    "    temp_ = pd.DataFrame(hourly_range).rename(columns={0:'hour'})\n",
    "    temp_['id'] = i\n",
    "    list_empty_dataframe.append(temp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the empty dataframes\n",
    "df_hourly_injured = pd.concat(list_empty_dataframe, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframe. By doing this, we will get the number of crashes per each short segment, \n",
    "# and there will be NaN values if there is no crashes at a certain segment and hour\n",
    "df_hourly_injured = df_hourly_injured.merge(df_crash_short_segment_hourly_injured,\n",
    "                                        left_on=['id','hour'],\n",
    "                                        right_on=['nearest_id','hour'],\n",
    "                                        how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "df_hourly_injured = df_hourly_injured.drop('nearest_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN values as 0\n",
    "df_hourly_injured = df_hourly_injured.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype to int\n",
    "df_hourly_injured['number_of_injured'] = df_hourly_injured['number_of_injured'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing same things regarding number of killed people\n",
    "df_crash_short_segment_hourly_killed =  gdf_crash_short_segment[['nearest_id',\n",
    "                                                                 'hour',\n",
    "                                                                 'number_of_killed']].groupby(['nearest_id',\n",
    "                                                                                               'hour'],\n",
    "                                                                                            as_index=False).sum()\n",
    "df_hourly_killed = pd.concat(list_empty_dataframe, axis=0)\n",
    "df_hourly_killed = df_hourly_killed.merge(df_crash_short_segment_hourly_killed,\n",
    "                                        left_on=['id','hour'],\n",
    "                                        right_on=['nearest_id','hour'],\n",
    "                                        how='left')\n",
    "df_hourly_killed = df_hourly_killed.drop('nearest_id', axis=1)\n",
    "df_hourly_killed = df_hourly_killed.fillna(0)\n",
    "df_hourly_killed['number_of_killed'] = df_hourly_killed['number_of_killed'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To minimize the size of the csv file, we will save the number of crashes as a list\n",
    "df_hourly_injured_list = df_hourly_injured[['id','number_of_injured']].groupby('id')['number_of_injured'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "00010fd3ee560483c21bb98e414741c7    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, ...\n",
       "0006da955dbe286a729ac6847ec22e6f    [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "00217e287463d24d9b0e8d20efa9e511    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "00520114b0a7f9d36eafa7e42f03196e    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, ...\n",
       "0059632c4bd2f573e9c2beed50983686    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...\n",
       "Name: number_of_injured, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the list was created by time order\n",
    "df_hourly_injured_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hourly_injured.loc[df_hourly_injured['id']=='00010fd3ee560483c21bb98e414741c7']['number_of_injured'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To minimize the size of the csv file, we will save the number of crashes as a list\n",
    "df_hourly_killed_list = df_hourly_killed[['id','number_of_killed']].groupby('id')['number_of_killed'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "00010fd3ee560483c21bb98e414741c7    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "0006da955dbe286a729ac6847ec22e6f    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "00217e287463d24d9b0e8d20efa9e511    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "00520114b0a7f9d36eafa7e42f03196e    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "0059632c4bd2f573e9c2beed50983686    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "                                                          ...                        \n",
       "ffa76979180bc70451bbd5be891b4b13    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "ffb39397b1f0b732ac9f22c5190a8513    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "ffd7ebaa31da02967746ade3e93cf756    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "ffe965dbb2a41f3288a679d2c0451c49    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "ffedf771d90e31a9e03ac80241e58b50    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: number_of_killed, Length: 5340, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hourly_killed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two dataframes\n",
    "df_list = pd.DataFrame(df_hourly_injured_list).merge(pd.DataFrame(df_hourly_killed_list), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "df_list.to_csv('../data/cleaned_data/crash_aggregation/crash_short_segment_hourly_injured.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same process with the 'short segment' part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that you run the 'shst_02_extract_short_segments' notebook to get the 'shst_node_filtered.shp'\n",
    "# import a shapefile of the node point\n",
    "gdf_node = gpd.read_file('../data/sharedstreets_geometry/node_filtered/shst_node_filtered.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that you run the 'crash_02_define_Intersection_crash' notebook to get the 'crash_intersection.shp'\n",
    "# import crash dataset\n",
    "gdf_crash_node = gpd.read_file('../data/cleaned_data/crash_seperated/crash_intersection/crash_intersection.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['collision_', 'nearest_no', 'crash_date', 'crash_time', 'borough',\n",
       "       'zip_code', 'on_street_', 'cross_stre', 'off_street', 'number_of_',\n",
       "       'number_o_1', 'number_o_2', 'number_o_3', 'number_o_4', 'number_o_5',\n",
       "       'number_o_6', 'number_o_7', 'contributi', 'contribu_1', 'contribu_2',\n",
       "       'contribu_3', 'contribu_4', 'vehicle_ty', 'vehicle__1', 'vehicle__2',\n",
       "       'vehicle__3', 'vehicle__4', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_crash_node.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "gdf_crash_node = gdf_crash_node.rename(columns={'collision_':'collision_id',\n",
    "                                                'nearest_no':'node_id',\n",
    "                                                'number_of_': 'number_of_injured',\n",
    "                                                'number_o_1': 'number_of_killed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type of crash_time column\n",
    "gdf_crash_node['crash_time'] = pd.to_datetime(gdf_crash_node['crash_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for hour when crash occure\n",
    "gdf_crash_node['hour'] = gdf_crash_node['crash_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by 'node_id'\n",
    "df_crash_node_hourly_injured =  gdf_crash_node[['node_id',\n",
    "                                                'hour',\n",
    "                                                'number_of_injured']].groupby(['node_id',\n",
    "                                                                               'hour'],\n",
    "                                                                               as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list of hours in a day and node points\n",
    "hourly_range = list(range(0,24))\n",
    "list_node_id =gdf_node['node_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list of empty dataframe per segment. In each empty dataframe, 24 rows will be created per segments\n",
    "list_empty_dataframe = []\n",
    "for i in list_node_id:\n",
    "    temp_ = pd.DataFrame(hourly_range).rename(columns={0:'hour'})\n",
    "    temp_['id'] = i\n",
    "    list_empty_dataframe.append(temp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the empty dataframes\n",
    "df_hourly_injured = pd.concat(list_empty_dataframe, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframe. By doing this, we will get the number of crashes per each short segment, \n",
    "# and there will be NaN values if there is no crashes at a certain segment and hour\n",
    "df_hourly_injured = df_hourly_injured.merge(df_crash_node_hourly_injured,\n",
    "                                        left_on=['id','hour'],\n",
    "                                        right_on=['node_id','hour'],\n",
    "                                        how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "df_hourly_injured = df_hourly_injured.drop('node_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN values as 0\n",
    "df_hourly_injured = df_hourly_injured.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype to int\n",
    "df_hourly_injured['number_of_injured'] = df_hourly_injured['number_of_injured'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing same things regarding number of killed people\n",
    "df_crash_node_hourly_killed =  gdf_crash_node[['node_id',\n",
    "                                               'hour',\n",
    "                                               'number_of_killed']].groupby(['node_id',\n",
    "                                                                             'hour'],\n",
    "                                                                              as_index=False).sum()\n",
    "df_hourly_killed = pd.concat(list_empty_dataframe, axis=0)\n",
    "df_hourly_killed = df_hourly_killed.merge(df_crash_node_hourly_killed,\n",
    "                                        left_on=['id','hour'],\n",
    "                                        right_on=['node_id','hour'],\n",
    "                                        how='left')\n",
    "df_hourly_killed = df_hourly_killed.drop('node_id', axis=1)\n",
    "df_hourly_killed = df_hourly_killed.fillna(0)\n",
    "df_hourly_killed['number_of_killed'] = df_hourly_killed['number_of_killed'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To minimize the size of the csv file, we will save the number of crashes as a list\n",
    "df_hourly_injured_list = df_hourly_injured[['id','number_of_injured']].groupby('id')['number_of_injured'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To minimize the size of the csv file, we will save the number of crashes as a list\n",
    "df_hourly_killed_list = df_hourly_killed[['id','number_of_killed']].groupby('id')['number_of_killed'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two dataframes\n",
    "df_list = pd.DataFrame(df_hourly_injured_list).merge(pd.DataFrame(df_hourly_killed_list), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "df_list.to_csv('../data/cleaned_data/crash_aggregation/crash_node_hourly_injured.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that you run the 'shst_02_extract_short_segments' notebook to get the 'shst_segment_filtered.shp'\n",
    "# import a shapefile of the short segment centroid\n",
    "gdf_segment = gpd.read_file('../data/sharedstreets_geometry/segment_filtered/shst_segment_filtered.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fromInters</th>\n",
       "      <th>toIntersec</th>\n",
       "      <th>forwardRef</th>\n",
       "      <th>backRefere</th>\n",
       "      <th>roadClass</th>\n",
       "      <th>length</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>db6792075ebbddc84479fda26174ca30</td>\n",
       "      <td>374b01a56e64379b8d7198962eaede90</td>\n",
       "      <td>2922a5babc5f921116a9fed4131a5bb1</td>\n",
       "      <td>48b7ab8e4cbafb2c1893cd682ded6704</td>\n",
       "      <td>a8475c8bd67f9e0ec8ce6a404aae41c1</td>\n",
       "      <td>Residential</td>\n",
       "      <td>299.421958</td>\n",
       "      <td>LINESTRING (-73.91694 40.64668, -73.91625 40.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42ccdc2b9ebc38f98c22bb0035045628</td>\n",
       "      <td>37db438d57f16f92e5ba91f1ad1793bb</td>\n",
       "      <td>374b01a56e64379b8d7198962eaede90</td>\n",
       "      <td>febaf06db79d8a16588d1c387a62fdb2</td>\n",
       "      <td>9db38906c3d8ae5df463e297be4e2b9b</td>\n",
       "      <td>Residential</td>\n",
       "      <td>256.577253</td>\n",
       "      <td>LINESTRING (-73.91765 40.64623, -73.91732 40.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84afb6627019b793945a7aab1feefe77</td>\n",
       "      <td>374b01a56e64379b8d7198962eaede90</td>\n",
       "      <td>5b6e4972c82ad4eb6d24c17b94b33b59</td>\n",
       "      <td>3f53ec240fc39c6b6810243b5b6fc830</td>\n",
       "      <td>fbbb71d35b794421e030d3ec9e1dcede</td>\n",
       "      <td>Residential</td>\n",
       "      <td>264.356932</td>\n",
       "      <td>LINESTRING (-73.91694 40.64668, -73.91662 40.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cce2402bd9841cb406b283d10a814940</td>\n",
       "      <td>5b6e4972c82ad4eb6d24c17b94b33b59</td>\n",
       "      <td>a3e9299f85dbecb22e829acc84c10e0e</td>\n",
       "      <td>3087b5f676af0e0026291f350b24859f</td>\n",
       "      <td>2b5b359caf490894be2d52ac51ebd0aa</td>\n",
       "      <td>Residential</td>\n",
       "      <td>256.824988</td>\n",
       "      <td>LINESTRING (-73.91621 40.64715, -73.91550 40.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9fed2268f9da5e9d263fdec0cb322aaa</td>\n",
       "      <td>5b6e4972c82ad4eb6d24c17b94b33b59</td>\n",
       "      <td>4701018d0dd721de27e208b19f0b20b6</td>\n",
       "      <td>4e2b3b2e438d9d7d504c1f0c76a5e4b0</td>\n",
       "      <td>564d3c4d11cb8340bfa4cc2b1ac2e6ff</td>\n",
       "      <td>Residential</td>\n",
       "      <td>378.440368</td>\n",
       "      <td>LINESTRING (-73.91621 40.64715, -73.91611 40.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                        fromInters  \\\n",
       "0  db6792075ebbddc84479fda26174ca30  374b01a56e64379b8d7198962eaede90   \n",
       "1  42ccdc2b9ebc38f98c22bb0035045628  37db438d57f16f92e5ba91f1ad1793bb   \n",
       "2  84afb6627019b793945a7aab1feefe77  374b01a56e64379b8d7198962eaede90   \n",
       "3  cce2402bd9841cb406b283d10a814940  5b6e4972c82ad4eb6d24c17b94b33b59   \n",
       "4  9fed2268f9da5e9d263fdec0cb322aaa  5b6e4972c82ad4eb6d24c17b94b33b59   \n",
       "\n",
       "                         toIntersec                        forwardRef  \\\n",
       "0  2922a5babc5f921116a9fed4131a5bb1  48b7ab8e4cbafb2c1893cd682ded6704   \n",
       "1  374b01a56e64379b8d7198962eaede90  febaf06db79d8a16588d1c387a62fdb2   \n",
       "2  5b6e4972c82ad4eb6d24c17b94b33b59  3f53ec240fc39c6b6810243b5b6fc830   \n",
       "3  a3e9299f85dbecb22e829acc84c10e0e  3087b5f676af0e0026291f350b24859f   \n",
       "4  4701018d0dd721de27e208b19f0b20b6  4e2b3b2e438d9d7d504c1f0c76a5e4b0   \n",
       "\n",
       "                         backRefere    roadClass      length  \\\n",
       "0  a8475c8bd67f9e0ec8ce6a404aae41c1  Residential  299.421958   \n",
       "1  9db38906c3d8ae5df463e297be4e2b9b  Residential  256.577253   \n",
       "2  fbbb71d35b794421e030d3ec9e1dcede  Residential  264.356932   \n",
       "3  2b5b359caf490894be2d52ac51ebd0aa  Residential  256.824988   \n",
       "4  564d3c4d11cb8340bfa4cc2b1ac2e6ff  Residential  378.440368   \n",
       "\n",
       "                                            geometry  \n",
       "0  LINESTRING (-73.91694 40.64668, -73.91625 40.6...  \n",
       "1  LINESTRING (-73.91765 40.64623, -73.91732 40.6...  \n",
       "2  LINESTRING (-73.91694 40.64668, -73.91662 40.6...  \n",
       "3  LINESTRING (-73.91621 40.64715, -73.91550 40.6...  \n",
       "4  LINESTRING (-73.91621 40.64715, -73.91611 40.6...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_segment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that you run the 'crash_02_define_Intersection_crash' notebook to get the 'crash_segment.shp'\n",
    "# import crash dataset\n",
    "gdf_crash_segment = gpd.read_file('../data/cleaned_data/crash_seperated/crash_segment/crash_segment.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['collision_', 'geometry_i', 'crash_date', 'crash_time', 'borough',\n",
       "       'zip_code', 'on_street_', 'cross_stre', 'off_street', 'number_of_',\n",
       "       'number_o_1', 'number_o_2', 'number_o_3', 'number_o_4', 'number_o_5',\n",
       "       'number_o_6', 'number_o_7', 'contributi', 'contribu_1', 'contribu_2',\n",
       "       'contribu_3', 'contribu_4', 'vehicle_ty', 'vehicle__1', 'vehicle__2',\n",
       "       'vehicle__3', 'vehicle__4', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_crash_segment.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "gdf_crash_segment = gdf_crash_segment.rename(columns={'collision_':'collision_id',\n",
    "                                                      'geometry_i':'geometry_id',\n",
    "                                                      'number_of_': 'number_of_injured',\n",
    "                                                      'number_o_1': 'number_of_killed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type of crash_time column\n",
    "gdf_crash_segment['crash_time'] = pd.to_datetime(gdf_crash_segment['crash_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for hour when crash occure\n",
    "gdf_crash_segment['hour'] =gdf_crash_segment['crash_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by 'node_id'\n",
    "df_crash_segment_hourly_injured =  gdf_crash_segment[['geometry_id',\n",
    "                                                      'hour',\n",
    "                                                      'number_of_injured']].groupby(['geometry_id',\n",
    "                                                                                     'hour'],\n",
    "                                                                                     as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list of hours in a day and node points\n",
    "hourly_range = list(range(0,24))\n",
    "list_segment_id =gdf_segment['id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list of empty dataframe per segment. In each empty dataframe, 24 rows will be created per segments\n",
    "list_empty_dataframe = []\n",
    "for i in list_segment_id:\n",
    "    temp_ = pd.DataFrame(hourly_range).rename(columns={0:'hour'})\n",
    "    temp_['id'] = i\n",
    "    list_empty_dataframe.append(temp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the empty dataframes\n",
    "df_hourly_injured = pd.concat(list_empty_dataframe, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframe. By doing this, we will get the number of crashes per each short segment, \n",
    "# and there will be NaN values if there is no crashes at a certain segment and hour\n",
    "df_hourly_injured = df_hourly_injured.merge(df_crash_segment_hourly_injured,\n",
    "                                        left_on=['id','hour'],\n",
    "                                        right_on=['geometry_id','hour'],\n",
    "                                        how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "df_hourly_injured = df_hourly_injured.drop('geometry_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN values as 0\n",
    "df_hourly_injured = df_hourly_injured.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype to int\n",
    "df_hourly_injured['number_of_injured'] = df_hourly_injured['number_of_injured'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing same things regarding number of killed people\n",
    "df_crash_segment_hourly_killed =  gdf_crash_segment[['geometry_id',\n",
    "                                                      'hour',\n",
    "                                                      'number_of_killed']].groupby(['geometry_id',\n",
    "                                                                                    'hour'],\n",
    "                                                                                     as_index=False).sum()\n",
    "df_hourly_killed = pd.concat(list_empty_dataframe, axis=0)\n",
    "df_hourly_killed = df_hourly_killed.merge(df_crash_segment_hourly_killed,\n",
    "                                        left_on=['id','hour'],\n",
    "                                        right_on=['geometry_id','hour'],\n",
    "                                        how='left')\n",
    "df_hourly_killed = df_hourly_killed.drop('geometry_id', axis=1)\n",
    "df_hourly_killed = df_hourly_killed.fillna(0)\n",
    "df_hourly_killed['number_of_killed'] = df_hourly_killed['number_of_killed'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To minimize the size of the csv file, we will save the number of crashes as a list\n",
    "df_hourly_injured_list = df_hourly_injured[['id','number_of_injured']].groupby('id')['number_of_injured'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To minimize the size of the csv file, we will save the number of crashes as a list\n",
    "df_hourly_killed_list = df_hourly_killed[['id','number_of_killed']].groupby('id')['number_of_killed'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two dataframes\n",
    "df_list = pd.DataFrame(df_hourly_injured_list).merge(pd.DataFrame(df_hourly_killed_list), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "df_list.to_csv('../data/cleaned_data/crash_aggregation/crash_segment_hourly_injured.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
